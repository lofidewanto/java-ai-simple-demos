spring.application.name=demo-spriai

# Logging Configuration
logging.level.org.springframework.ai=debug
logging.level.org.springframework.ai.chat=trace
logging.level.org.springframework.ai.ollama=trace
logging.level.org.springframework.web.client.RestTemplate=trace
logging.level.org.springframework.web=debug
logging.level.com.example.demo=debug

# Show request/response details
logging.level.org.springframework.web.client=trace

# Ollama Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=gpt-oss:20b
spring.ai.ollama.chat.options.temperature=0.7
spring.ai.ollama.chat.options.top-k=40
spring.ai.ollama.chat.options.top-p=0.9
spring.ai.ollama.chat.options.num-predict=10000
spring.ai.ollama.init.pull-model-strategy=never
spring.ai.ollama.init.timeout=10m
spring.ai.ollama.init.max-retries=3